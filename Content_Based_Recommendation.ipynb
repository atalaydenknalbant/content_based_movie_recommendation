{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1513a3",
   "metadata": {},
   "source": [
    "# Content-based Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec61265",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca31c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "import os\n",
    "device = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c60c6a",
   "metadata": {},
   "source": [
    "## Initialize OMBD api to fetch plot summaries then save it as plots.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6d083",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df22cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest-small\\ratings.csv\")\n",
    "# links = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest-small\\links.csv\")\n",
    "# tags = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest-small\\tags.csv\")\n",
    "# movies = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest-small\\movies.csv\")\n",
    "# plots = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest-small\\plots.csv\")\n",
    "ratings = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest\\ratings.csv\")\n",
    "links = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest\\links.csv\")\n",
    "tags = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest\\tags.csv\")\n",
    "movies = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest\\movies.csv\")\n",
    "plots = pd.read_csv(r\"C:\\Users\\yineh\\OneDrive\\Masaüstü\\ml-latest\\plots.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d62bf7",
   "metadata": {},
   "source": [
    "## Merge movie tags into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e141c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tags = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x.dropna().astype(str))).reset_index()\n",
    "movies = movies.merge(movie_tags, on='movieId', how='inner')\n",
    "movies = movies.merge(plots[['movieId', 'plot_summary']], on='movieId', how='inner')\n",
    "movies = movies.dropna(subset=['tag', 'plot_summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3c8e3",
   "metadata": {},
   "source": [
    "## Combine Tags and Plot Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa923af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(row):\n",
    "    return f\"Movie Plot: {row['plot_summary']} Keywords: {row['tag']}\"\n",
    "\n",
    "movies['plots_tags'] = movies.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe15873",
   "metadata": {},
   "source": [
    "## Clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text_data(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "#     return text\n",
    "\n",
    "# tqdm.pandas(desc=\"Cleaning Text\")\n",
    "# movies['plots_tags'] = movies['plots_tags'].progress_apply(clean_text_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ce6a2",
   "metadata": {},
   "source": [
    "## Reset Movie Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d856e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.reset_index(drop=True, inplace=True)\n",
    "movie_indices = pd.Series(movies.index, index=movies['movieId']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f409f",
   "metadata": {},
   "source": [
    "## Initialize the pre-trained language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc7b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371d3d0",
   "metadata": {},
   "source": [
    "## Generate embeddings for all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f90ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file not found. Generating embeddings from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings in Batches: 100%|██████████| 829/829 [35:27<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to movie_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "embedding_path = 'movie_embeddings.pt'\n",
    "\n",
    "# Function to save embeddings\n",
    "def save_embeddings(embeddings, path=embedding_path):\n",
    "    torch.save(embeddings, path)\n",
    "    print(f\"Embeddings saved to {path}\")\n",
    "\n",
    "# Function to load embeddings\n",
    "def load_embeddings(path=embedding_path):\n",
    "    if os.path.exists(path):\n",
    "        embeddings = torch.load(path, map_location=device)\n",
    "        print(f\"Embeddings loaded from {path}\")\n",
    "        return embeddings\n",
    "    else:\n",
    "        print(\"Embedding file not found. Generating embeddings from scratch.\")\n",
    "        return None\n",
    "\n",
    "# Check if embeddings are already saved; load if available, otherwise generate and save\n",
    "movie_embeddings = load_embeddings()\n",
    "movie_embeddings = movie_embeddings.type(torch.FloatTensor).to(device)\n",
    "if movie_embeddings is None:\n",
    "    # Generate embeddings as before\n",
    "    documents = movies['plots_tags'].tolist()\n",
    "    batch_size = 64\n",
    "    movie_embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(documents), batch_size), desc=\"Generating Embeddings in Batches\"):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        batch_embeddings = model.encode(batch, convert_to_tensor=True, show_progress_bar=False)\n",
    "        movie_embeddings.append(batch_embeddings.to(device))\n",
    "\n",
    "    movie_embeddings = torch.cat(movie_embeddings)\n",
    "    \n",
    "    # Save embeddings after generating them\n",
    "    save_embeddings(movie_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425fe00",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa1d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000001 , 0.56306165, 0.5670217 , ..., 0.49139744, 0.5040304 ,\n",
       "       0.4888566 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine_sim = cosine_similarity(movie_embeddings.cpu())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f31f10",
   "metadata": {},
   "source": [
    "## Filter ratings to include only movies present in the movies DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c513b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[ratings['movieId'].isin(movies['movieId'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4cb895",
   "metadata": {},
   "source": [
    "## Predict rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, movie_id):\n",
    "    user_ratings = ratings[ratings['userId'] == user_id]\n",
    "    user_movie_ids = user_ratings['movieId'].values\n",
    "\n",
    "    if movie_id not in movie_indices.index or len(user_movie_ids) == 0:\n",
    "        return ratings['rating'].mean()\n",
    "\n",
    "    idx = movie_indices[movie_id]\n",
    "    target_vector = movie_embeddings[idx].unsqueeze(0)\n",
    "\n",
    "    user_indices = user_ratings['movieId'].map(movie_indices).dropna().astype(int)\n",
    "    if len(user_indices) == 0:\n",
    "        return ratings['rating'].mean()\n",
    "\n",
    "    user_indices_list = user_indices.tolist()\n",
    "    user_vectors = movie_embeddings[user_indices_list]\n",
    "    ratings_values = user_ratings['rating'].values\n",
    "\n",
    "    # Convert ratings to tensor\n",
    "    ratings_tensor = torch.tensor(ratings_values, device=device)\n",
    "\n",
    "    # Compute similarities on GPU\n",
    "    similarities = torch.nn.functional.cosine_similarity(target_vector, user_vectors)\n",
    "\n",
    "    # Handle zero similarity case\n",
    "    if torch.sum(similarities) == 0:\n",
    "        return ratings['rating'].mean()\n",
    "\n",
    "    # Compute predicted rating\n",
    "    predicted_rating = torch.dot(similarities, ratings_tensor) / torch.sum(similarities)\n",
    "    return predicted_rating.item()\n",
    "\n",
    "\n",
    "ratings_list = ratings.to_dict('records')\n",
    "\n",
    "def predict_rating_wrapper(row):\n",
    "    return predict_rating(row['userId'], row['movieId'])\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(tqdm(executor.map(predict_rating_wrapper, ratings_list), total=len(ratings_list), desc=\"Predicting Ratings\"))\n",
    "\n",
    "ratings['predicted_rating'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe516dc7",
   "metadata": {},
   "source": [
    "## Calculate Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d2a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.663473670155574\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(ratings['rating'], ratings['predicted_rating'])\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142b809",
   "metadata": {},
   "source": [
    "## Top-N Recommendation and Hit Ratio Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ac42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "\n",
    "positive_preferences = ratings\n",
    "test_size = 1000\n",
    "test_indices = np.random.choice(positive_preferences.index, size=test_size, replace=False)\n",
    "test_set = positive_preferences.loc[test_indices]\n",
    "\n",
    "train_set = ratings.drop(test_indices)\n",
    "ratings = train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(user_id, N=10):\n",
    "    user_rated_movie_ids = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
    "    user_indices = ratings[ratings['userId'] == user_id]['movieId'].map(movie_indices).dropna().astype(int)\n",
    "    user_ratings_values = ratings[ratings['userId'] == user_id]['rating'].values\n",
    "\n",
    "    if len(user_indices) == 0:\n",
    "        return []\n",
    "\n",
    "    user_indices_list = user_indices.tolist()\n",
    "    user_feature_vectors = movie_embeddings[user_indices_list]\n",
    "\n",
    "    # Convert ratings to tensor\n",
    "    user_ratings_tensor = torch.tensor(user_ratings_values, device=device)\n",
    "\n",
    "    # Compute user profile on GPU\n",
    "    user_profile = torch.sum(user_feature_vectors * user_ratings_tensor.unsqueeze(1), dim=0) / torch.sum(user_ratings_tensor)\n",
    "\n",
    "    # Compute similarities on GPU\n",
    "    similarities = torch.nn.functional.cosine_similarity(user_profile.unsqueeze(0), movie_embeddings).squeeze(0)\n",
    "\n",
    "    # Move similarities to CPU for further processing\n",
    "    similarities = similarities.cpu().numpy()\n",
    "\n",
    "    # Filter out movies already rated by the user\n",
    "    candidate_indices = [idx for idx in range(len(movies)) if movies.loc[idx, 'movieId'] not in user_rated_movie_ids]\n",
    "    candidate_similarities = similarities[candidate_indices]\n",
    "\n",
    "    # Get top N recommendations\n",
    "    top_N_indices = np.argsort(candidate_similarities)[-N:][::-1]\n",
    "    top_N_movie_indices = [candidate_indices[i] for i in top_N_indices]\n",
    "    top_N_movie_ids = movies.loc[top_N_movie_indices, 'movieId'].tolist()\n",
    "\n",
    "    return top_N_movie_ids\n",
    "\n",
    "\n",
    "def evaluate_top_n_recommendations(test_set, N=10):\n",
    "    total = len(test_set)\n",
    "\n",
    "    def evaluate_row(row):\n",
    "        user_id = row['userId']\n",
    "        test_movie_id = row['movieId']\n",
    "        recommended_movie_ids = get_top_n_recommendations(user_id, N)\n",
    "        return 1 if test_movie_id in recommended_movie_ids else 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(tqdm(executor.map(evaluate_row, (row for _, row in test_set.iterrows())), total=total, desc=\"Evaluating Recommendations\"))\n",
    "\n",
    "    hits = sum(results)\n",
    "    hit_ratio = hits / total\n",
    "    return hit_ratio\n",
    "\n",
    "N = 10\n",
    "hit_ratio = evaluate_top_n_recommendations(test_set, N)\n",
    "print(f'Hit Ratio: {hit_ratio}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
